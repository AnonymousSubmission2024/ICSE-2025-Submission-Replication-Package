We use both eyetracking and brain imaging to gather comprehensive data on participants' eye movements and brain activity, enabling a deeper understanding of their cognitive processes during software engineering tasks. In the following we provide the detailed settings of the devices.

* Eye Tracking
Eyetracking can provide objective measures of visual attention and has been increasingly used in studies of program comprehension in software engineering [1, 2, 3, 4]. Prior research has shown that several eyetracking based metrics such as fixation duration are indicators of cognitive effort. We refer readers to Rayner's work [5] for a general understanding, and to Sharafi et al. [4] for a software engineering-specific summary of different eyetracking metrics and their associations with various cognitive processes. For the purpose of this study, we focus primarily on fixation and saccade-based linearity metrics.

Throughout the experimental tasks, participants interact with the Atom IDE as their coding environment. We use the iTrace Atom plugin and gazel [6] to attribute gazes to specific source code elements and to process the raw gazes into fixations, respectively.

We employ the GazePoint GP3HD eyetracker for all of our experiments, which offers  a sampling rate of 150hz, with an accuracy of approximately 0.5–1 degrees of visual angle. This accuracy translates to an average error of 0.5 to 1 cm on a standard screen (equivalent to 19–38 pixels at 1920x1080 resolution). To mitigate the impact of this error, we set the source code's font size to 18 pt, resulting in an average error of one to three characters. 

For calibration, we employ a comprehensive approach by utilizing 9 gaze points, providing higher accuracy and coverage across the screen. To ensure the integrity of the collected eye tracking data, we establish a criterion for calibration quality, accepting only ratings of 4 out of 5 stars or higher. Calibration quality at these levels indicates an error of less than 0.7 and 0.5 degrees (equivalent to less than 19–30 pixels), respectively. Throughout the experimental tasks, participants interact with the Atom IDE as their coding environment. We use the iTrace Atom plugin to attribute gazes to specific source code elements, and gazel [6] to process the raw gazes into fixations. For fixation classification, we use the I-VT algorithm [7] with a velocity threshold of 80pixels/3ms velocity threshold, and minimum fixation duration threshold of 50ms. Before performing fixation classification, we interpolate invalid gazes to the nearest valid gaze (spatially and temporally), restricted to a within 50ms of the original gaze.

* Functional Near Infrared Spectroscopy (fNIRS)

Functional Near Infrared Spectroscopy (fNIRS) serves as an optical brain imaging technique, enabling the detection of changes in oxygenated and deoxygenated hemoglobin in the brain. This technique utilizes optical fibers to emit near-infrared light and measures blood oxygenation levels. Just like the Functional Magnetic Resonance Imaging (fMRI), fNIRS relies on the phenomenon of neurovascular coupling (changes in vascular dynamics in response to neuronal activity). Prior research has shown that fNIRS measured vascular metrics are highly correlated with measurements of the BOLD (blood-oxygenation- level-dependent) response using fMRI, which is widely considered the gold standard for brain imaging technology. However, unlike fMRI, fNIRS is portable and allows for conducting software engineering studies in more ecologically valid settings. 


For our experiments, we employ the fNIR2000s, a stand-alone functional brain imaging system shaped like a headband, which is manufactured by BIOPAC. The fNIR2000s focuses on measuring blood oxygenation levels in the prefrontal cortex, as prior studies have indicated that mentally demanding tasks require resources in this specific brain region. Notably, the fNIR2000s offers portability, ease of setup, and a lightweight design, making it a suitable choice for our experimental setup. We apply a low pass filter and baseline drift correction using fNIRSoft, Biopac's suite of post-processing software for their fNIRS devices.

[1] Peitek, Norman. "A neuro-cognitive perspective of program comprehension." Proceedings of the 40th International Conference on Software Engineering: Companion Proceeedings. 2018.
[2] Busjahn, Teresa, et al. "Eye tracking in computing education." Proceedings of the tenth annual conference on International computing education research. 2014.
[3] Sharafi, Zohreh, et al. "Toward an objective measure of developers’ cognitive activities." ACM Transactions on Software Engineering and Methodology (TOSEM) 30.3 (2021): 1-40.
[4] Sharafi, Zohreh, et al. "Eyes on code: A study on developers’ code navigation strategies." IEEE Transactions on Software Engineering 48.5 (2020): 1692-1704.
[5] Rayner, Keith. "Eye movements in reading and information processing: 20 years of research." Psychological bulletin 124.3 (1998): 372.
[6] Fakhoury, Sarah, et al. "gazel: Supporting source code edits in eye-tracking studies." 2021 IEEE/ACM 43rd International Conference on Software Engineering: Companion Proceedings (ICSE-Companion). IEEE, 2021.
[7] Salvucci, Dario D., and Joseph H. Goldberg. "Identifying fixations and saccades in eye-tracking protocols." Proceedings of the 2000 symposium on Eye tracking research & applications. 2000.
